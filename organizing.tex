\section{Introduction}

\section{Organizing in general}

After all the concerns has been addressed a pretty printing utility
will a nice final touch, ensuring a consistent structure inside ones
\file{bib} and having the same indentations and formatting for text.

\subsubsection{First step: Lex}
\begin{itemize}
\item Abbrev: should be handled by refactoring journal names into
  strings.
\end{itemize}

\subsubsection{Sec step: Consist}
\begin{itemize}
\item duplicate.  The tool should suggest merging when duplicates are
  found.
\item name change. When a forum name has changed it should suggest
  usage of a de-facto standard to highlight this.
\end{itemize}

\subsubsection{Configuration}

If relevant, refer to analyzing configuration and say the same
argument goes for organizing.


Having found the issues that are possible, a way to react to them is
needed.  Correcting is either done by changing the entries to a state,
where the analysis cannot find any more issues, or by using the
configurations to tell the analysis that the issues are false
positives.

There are two basic ways of reacting to the issues, one
automatically correcting them and the other is to present the issues
and have one decide what to do.  As pointed out in the problem
descriptions, it is hard, if not impossible, to automatically correct,
since it can lead to incorrect changes and thus introduce a new
structural issue.  Thus the organizing is done by presenting the
issues, letting the user decide on the action to take.

When presenting the user with the issues there are again two
approaches: letting one do a range of choices to handle the issues
finally outputting a corrected \file{bib}, or giving a list of issues
and suggestions for corrections.  The last one requires the user to
manually edit his \file{bib}, and if the issues are listed with line
numbers, they should be listed backwards, so the lines will be correct
throughout the correction.

A nice final touch would be to pretty print the \file{bib}, ensuring
consistent formatting.


\section{\orangutan}

\subsection{What}

{\orangutan} is designed as a framework rather as an end user
application.  The output it gives is the suggestions coming from the
analysis.  For instance, a tool listing the suggestions in a backward
order, for manual editing.


\subsection{How in principle}

The output given in JSON, which most programming frameworks support.
The output can be in a trimmed version showing only the detected
issues or in a full version containing all the entries.  Thus the
output be used for listing only the issues, or for printing an entire
corrected {\bibtex} file after choosing the desired solutions.


\subsection{How in practice}

{\orangutan} gives back a JSON string containing at least the entries
with detected issues.  If configured to do so, it keeps the entries
without issues.  For the entries in the output that has issues an
object is attached with the name \texttt{orangutan} detailing the
specific issues and suggestions.

The spell checker will add an object named $spelling$ to the
$orangutan$ object.  It contains the details from the spell check: how
many words it checked $wordCount$, how many misspellings it found
$misspellingCount$ and most importantly a list named $misspellings$
for the details from the spell checker.  Each item in $misspellings$
is an object consisting of: the misspelled word in $word$, the
position of the misspelled word in $position$ and a list of
suggestions inside $alternatives$.  An example of a spelling error can
be seen in \figref{fig:orgazing_misspelling_output}.

\begin{figure}
  \centering
\begin{minted}{json}
\end{minted}
\caption{An example of Orangutan output on a spelling error}
\label{fig:orgazing_misspelling_output}
\end{figure}

\remark{Now does it actually check for unknown entry types???}

When checking for correctness it marks entries according to the
{\bibtex} specification and de-facto standards.  This check is named
conformance check.  The output specifies when an entry type or a tag
is in violation with the rules specified.  The conformance checker
adds an object for the tags with conformance errors to the $orangutan$
object.  The object for the tag will then have an object named
$specificationConformance$ containing a description of the issue and a
code corresponding.

The current version just suggest the full name whenever an
abbreviation is detected.  Builds a structure with suggestions for
full names when an abbreviations is detected.

\section{Summary and conclusion}

To summarize:
